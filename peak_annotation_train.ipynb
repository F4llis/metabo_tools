{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Input\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "intensity_treshold = 8000 #  everything under this will be annotated false\n",
    "\n",
    "data_folder = '../data/sara_training/'\n",
    "peak_clarkii= data_folder + 'clarkiiT0I1_peak_annotations.csv' # data with peak: mz, rt, Y/N\n",
    "mz_clarkii = data_folder + 'clarkiiT0I1.mzML'\n",
    "peak_viridis= data_folder + 'viridisT0I2_peak_annotations.csv' # data with peak: mz, rt, Y/N\n",
    "mz_viridis = data_folder + 'viridisT0I2.mzML'\n",
    "\n",
    "pickle_path = './output/pickle_training.npy'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Factory:\n",
    "    def __init__(self):\n",
    "        self.X_ = []\n",
    "        self.y_ =  []\n",
    "        self.mz_ = []\n",
    "        self.rt_ =  []\n",
    "\n",
    "    def add_data(self, path_annotation, path_mz):\n",
    "        d = util.build_data_ml(path_annotation,path_mz )\n",
    "        self.X_ += d[0]\n",
    "        self.y_ +=  d[1]\n",
    "        self.mz_ += d[2]\n",
    "        self.rt_ +=  d[3]\n",
    "\n",
    "    def save(self, file_out):\n",
    "        with open(file_out, 'wb') as fi:\n",
    "            np.save(fi, np.asanyarray([self.X_,self.y_,self.mz_,self.rt_], dtype=object))\n",
    "\n",
    "    def load(self, file_out):\n",
    "        data = np.load(file_out, allow_pickle=True)\n",
    "        self.X_ = data[0]\n",
    "        self.y_ =  data[1]\n",
    "        self.mz_ = data[2]\n",
    "        self.rt_ =  data[3]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process input files and pickle it for later (only run once)\n",
    "data = Factory()\n",
    "data.add_data(peak_clarkii,mz_clarkii)\n",
    "data.add_data(peak_viridis,mz_viridis)\n",
    "data.save(pickle_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load data pickled\n",
    "data = np.load(pickle_path, allow_pickle=True)\n",
    "\n",
    "X_ = data[0]\n",
    "y_ =  data[1]\n",
    "mz_ = data[2]\n",
    "rt_ =  data[3]\n",
    "\n",
    "'''\n",
    "for i in range(len(X_)):\n",
    "    color = 'green' if y_[i] == 1 else 'red'\n",
    "    yn = 'YES' if y_[i] == 1 else 'NO'\n",
    "    plt.title(  str(i) + ' ' + yn + ' - ' + str(mz_[i]) + ' // ' + str(float(rt_[i])))\n",
    "    plt.plot(X_[i], color=color)\n",
    "    plt.show()\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def smooth(x,window_len=11,window='hanning'):\n",
    "    \"\"\"smooth the data using a window with requested size.\n",
    "\n",
    "    This method is based on the convolution of a scaled window with the signal.\n",
    "    The signal is prepared by introducing reflected copies of the signal\n",
    "    (with the window size) in both ends so that transient parts are minimized\n",
    "    in the begining and end part of the output signal.\n",
    "\n",
    "    input:\n",
    "        x: the input signal\n",
    "        window_len: the dimension of the smoothing window; should be an odd integer\n",
    "        window: the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\n",
    "            flat window will produce a moving average smoothing.\n",
    "\n",
    "    output:\n",
    "        the smoothed signal\n",
    "\n",
    "    example:\n",
    "\n",
    "    t=linspace(-2,2,0.1)\n",
    "    x=sin(t)+randn(len(t))*0.1\n",
    "    y=smooth(x)\n",
    "\n",
    "    see also:\n",
    "\n",
    "    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve\n",
    "    scipy.signal.lfilter\n",
    "\n",
    "    TODO: the window parameter could be the window itself if an array instead of a string\n",
    "    NOTE: length(output) != length(input), to correct this: return y[(window_len/2-1):-(window_len/2)] instead of just y.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if window_len<3:\n",
    "        return x\n",
    "\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    #print(len(s))\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "    return y\n",
    "\n",
    "def NormalizeData(data):\n",
    "    if np.max(data) - np.min(data) == 0.0:\n",
    "        return data\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_)\n",
    "\n",
    "df['y']= y_\n",
    "df['mz']= mz_\n",
    "df['rt']= rt_\n",
    "\n",
    "df['treshold_satisfied'] = df[0].apply(lambda x: 1 if np.amax(x) > intensity_treshold else 0)\n",
    "df['y'] = df['y'] & df['treshold_satisfied']\n",
    "df['y'] = df['y'].apply(lambda x: 1 if x == True else 0)\n",
    "\n",
    "df['norm'] = df[0].apply(lambda x: NormalizeData(x) )\n",
    "\n",
    "df['smooth'] = df[0].apply(lambda x: smooth(x) )\n",
    "df['smooth'] = df['smooth'].apply(lambda x: x[5:-5] )\n",
    "\n",
    "df['grad1'] = df['smooth'].apply(lambda x: np.gradient(x) )\n",
    "df['grad2'] = df['grad1'].apply(lambda x: np.gradient(x) )\n",
    "\n",
    "df['fft'] = df[0].apply(lambda x: np.fft.fft(x) )\n",
    "df['fftr'] = df['fft'].apply(lambda x: np.real(x) )\n",
    "df['ffti'] = df['fft'].apply(lambda x: np.real(np.imag(x)) )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xfft = np.hstack([np.array(df['treshold_satisfied']).reshape((len(df), -1)),np.vstack(df['fftr']), np.vstack(df['ffti'])] )\n",
    "print(xfft.shape)\n",
    "\n",
    "x = np.stack([ np.vstack(df['norm']), np.vstack(df['smooth']) ,\n",
    "              np.vstack(df['grad1']) , np.vstack(df['grad2'])  ] , axis = 2)\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ret_mats(df):\n",
    "    xfft = np.hstack( [np.array(df['treshold_satisfied']).reshape((len(df), -1)), np.vstack(df['fftr']), np.vstack(df['ffti'])] )\n",
    "    x = np.stack([ np.vstack(df['norm']), np.vstack(df['smooth']) ,\n",
    "              np.vstack(df['grad1']) , np.vstack(df['grad2'])  ] , axis = 2)\n",
    "    y = df.y.map(lambda x : float(x))\n",
    "\n",
    "    return x,xfft,y\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "mats={'train':ret_mats(train), 'test':ret_mats(test)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = None\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "inputvec = Input(shape=(120,4))\n",
    "inputfft = Input(shape=(241))\n",
    "\n",
    "lstm = LSTM(50,  return_sequences = True , return_state = False, dropout=0.2,\n",
    "    recurrent_dropout=0.2, go_backwards=True)\n",
    "\n",
    "whole_seq_output = lstm(inputvec)\n",
    "\n",
    "lstm2 = LSTM(40, return_sequences = True , return_state = False, dropout=0.2,\n",
    "    recurrent_dropout=0.2, go_backwards=True )\n",
    "\n",
    "whole_seq_output2 = lstm2(whole_seq_output)\n",
    "\n",
    "lstm3 = LSTM(30, return_sequences = False , return_state = True, dropout=0.2,\n",
    "    recurrent_dropout=0.2, go_backwards=True )\n",
    "\n",
    "final_memory_state, final_carry_state, whole_seq_output = lstm3(whole_seq_output2)\n",
    "\n",
    "dense_input = tf.keras.layers.Concatenate()([final_memory_state, final_carry_state,whole_seq_output, inputfft])\n",
    "dense_input = tf.keras.layers.Dropout(.2)(dense_input)\n",
    "output1 = Dense(50)(dense_input)\n",
    "output1 = tf.keras.layers.Dropout(.2)(output1)\n",
    "output = Dense(25)(output1)\n",
    "final = Dense(1,activation = 'sigmoid')(output)\n",
    "\n",
    "\n",
    "model = Model( inputs = [inputvec,inputfft] , outputs = final)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam( learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit([mats['train'][0], mats['train'][1]], mats['train'][2], epochs=100, batch_size=250)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/clementtrain/work/metabolomics/env_metabo/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 307ms/step - loss: 33670.6992 - accuracy: 0.9298\n",
      "[33670.69921875, 0.9297658801078796]\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([ mats['test'][0], mats['test'][1]], mats['test'][2], verbose=1)\n",
    "print(scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save('output/model_peak')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pre_raw = model.predict([ mats['test'][0], mats['test'][1]])\n",
    "\n",
    "pre = [1 if  pr > 0.5 else 0 for pr in pre_raw ]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "false = 0\n",
    "small_all = 0\n",
    "\n",
    "fp = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "fp_small = 0\n",
    "fn_small = 0\n",
    "\n",
    "\n",
    "cpt =0\n",
    "\n",
    "for p in pre:\n",
    "\n",
    "    df_key = list(mats['test'][2].keys())[cpt]\n",
    "\n",
    "    dfdf = df[0][df_key]\n",
    "\n",
    "    if max(dfdf) < 8000:\n",
    "        small_all +=1\n",
    "\n",
    "    if p != list(mats['test'][2])[cpt]:\n",
    "\n",
    "        if p == 1:\n",
    "            fp +=1\n",
    "        else:\n",
    "            fn +=1\n",
    "\n",
    "\n",
    "        plt.title( 'WRONG' + str(df['mz'][df_key]) )\n",
    "        color = 'green' if p == 1 else 'red'\n",
    "        plt.plot(dfdf , color = color)\n",
    "        plt.show()\n",
    "\n",
    "        if max(dfdf) < 8000:\n",
    "            if p == 1:\n",
    "                fp_small +=1\n",
    "            else:\n",
    "                fn_small +=1\n",
    "\n",
    "        false +=1\n",
    "\n",
    "\n",
    "    else:\n",
    "        if p == 1:\n",
    "            tp +=1\n",
    "        else:\n",
    "            tn +=1\n",
    "\n",
    "        plt.title( 'GOOD' + str(df['mz'][df_key]) )\n",
    "        color = 'green' if p == 1 else 'red'\n",
    "        plt.plot(dfdf , color = color)\n",
    "        plt.show()\n",
    "\n",
    "    cpt +=1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Features:  299\n",
      "False Predictions:  21\n",
      "% Good:  92.97658862876254\n",
      "\n",
      "\n",
      "TP 7\n",
      "TN 271\n",
      "FP 14\n",
      "FN 7\n",
      "\n",
      "\n",
      "Precision:  33.333333333333336\n",
      "Recall:  50.0\n",
      "\n",
      "\n",
      "< 8000  FP:  8\n",
      "< 8000  FN:  0\n",
      "< 8000 Totals:  259\n",
      "\n",
      "\n",
      "Corrected Precision:  53.84615384615385\n",
      "Corrected Recall:  50.0\n",
      "Corrected % Good:  95.65217391304348\n"
     ]
    }
   ],
   "source": [
    "total = len( mats['test'][0])\n",
    "print('Predicted Features: ', total)\n",
    "print('False Predictions: ', false)\n",
    "print('% Good: ', (total-false)/total*100)\n",
    "print('\\n')\n",
    "\n",
    "print('TP', tp)\n",
    "print('TN', tn)\n",
    "print('FP', fp)\n",
    "print('FN', fn)\n",
    "print('\\n')\n",
    "\n",
    "print('Precision: ', (100 * tp)/ (tp+fp) )\n",
    "print('Recall: ', (100 * tp/ (tp+fn) ))\n",
    "print('\\n')\n",
    "\n",
    "print('< 8000  FP: ', fp_small)\n",
    "print('< 8000  FN: ', fn_small)\n",
    "print('< 8000 Totals: ', small_all)\n",
    "print('\\n')\n",
    "\n",
    "print('Corrected Precision: ', (100 * tp)/ (tp+fp-fp_small) )\n",
    "print('Corrected Recall: ', (100 * tp/ (tp+fn-fn_small) ))\n",
    "print('Corrected % Good: ', (total-false+fp_small)/total*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}